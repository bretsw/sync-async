---
title: "Sync-Async Analysis"
author: "Removed for Peer Review"
date: "6/7/2019"
output: 
    html_document:
        toc: true
        float_toc: true
---

# Loading the data and setting up

This section loads the data and packages and starts to process the data, but doesn't calculate any statistics or create any results.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
usethis::use_git_ignore(c("*.csv", "*.rds"))
```

## Loading packages

```{r, include=FALSE}
library(tidyverse)
library(rtweet)
library(lubridate)
library(janitor)
library(Hotelling)
library(devtools)
# devtools::install_github("jrosen48/tidyttest")  # only need to run once
library(tidyttest)
```

## Getting data from Open Science Framework

For notes on this one-time setup, see this walkthrough: http://centerforopenscience.github.io/osfr/articles/auth.html)

First, you must generate an API token from an OSF account that has been added to the data repository. Read how to do this here: https://developer.osf.io/#tag/General-Usage

Then, you need to add the OSF API token to the `.renviron` file, which is created using the following command. Here, the file is created at the user level, although this could also be set to the project level. 

```{r, eval = FALSE}
usethis::edit_r_environ(scope='user')
```

Open the `.renviron` file and add a single line, using this exact text but replacing `<token>` with your OSF API token:  
`OSF_PAT="<token>"`

Save the file, quit R, and restart in a new session. Continue running the R script from here.

--------------------------------------------------------------------------------

Now, install the `osfr` package and load the library:

```{r, eval = FALSE}
devtools::install_github("centerforopenscience/osfr")   # only need to run once
library(osfr)
```

Upon loading the `osfr` package, you should see this message:  
`Automatically registered OSF personal access token.` 

Now you are able to retrieve and download the relevant dataset with this code:

```{r, eval = FALSE}
osf_retrieve_file("https://osf.io/pxmfc/") %>% 
    osf_download(path = "anonymized-dataset.csv", overwrite = TRUE)
```

## Loading the data

Note that we first processed data collected via TAGS (tags.hawksey.info) in order to obtain the tweet IDs, which we then passed to the `lookup_statuses()` rtweet function. We also processed that data to join it with LIWC data and to remove identifying information.

```{r}
d <- read_csv("anonymized-dataset.csv")
```

## Processing the data

```{r}
reply_tweets <- d %>% 
    mutate(is_reply = !is.na(reply_to_status_id)) %>% 
    filter(is_reply) %>% 
    count(reply_to_status_id) %>% 
    rename(replies_count = n)

length_with_na <- function(x) {
  ifelse(is.na(x), 0, map_int(x, length))
}

proc_tweets <- function(d) {
  d %>%
    mutate(mentions_count = length_with_na(str_split(mentions_screen_name, " ")),
           #hashtags_count = length_with_na(str_split(hashtags, " ")),
           #urls_count = length_with_na(str_split(urls_url, " ")),
           is_reply = if_else(!is.na(reply_to_status_id), TRUE, FALSE))
}

d <- proc_tweets(d)

is.na(d$is_sync) %>% which()  # check to make sure there are no NAs

prepped_data <- d %>% 
    filter(!is_retweet) %>% 
    mutate(reply_to_status_id = status_id) %>% 
    left_join(reply_tweets, by = "reply_to_status_id") %>% 
    mutate(replies_count = ifelse(is.na(replies_count), 0, replies_count)) %>% 
    select(screen_name, is_sync,
           social, cogproc, posemo, negemo, work,
           favorite_count, retweet_count, replies_count, 
           mentions_count, hashtags_count, urls_count) %>% 
    rename(Social = social,
           `Cognitive Processing` = cogproc,
           `Positive Affect` = posemo,
           `Negative Affect` = negemo,
           `Work-related Concerns` = work) %>% 
    rename(Likes = favorite_count,
           Retweets = retweet_count,
           Replies = replies_count,
           Mentions = mentions_count) %>% 
    rename(Hashtags = hashtags_count,
           URLs = urls_count)
```

# RQ1: Activity

## Plot: Sync vs. Async

```{r}
d$created_at_m <- d$created_at - lubridate::hours(5)
d$date_r <- d$created_at_m %>% floor_date("day")

to_plot <- d %>% count(date_r, is_sync) %>% as.data.frame %>%
    tidyr::complete(date_r, is_sync, fill = list(n = 0)) %>%
    filter(date_r != ymd("2015-08-31")) %>%
    mutate(date_r = date_r %>% as_date,
           during_sync_chat = as.factor(is_sync)
    ) 
levels(to_plot$during_sync_chat) <- c('Not During a Chat (Asynchronous)',
                                      'During a Chat (Synchronous)')

to_plot_sync <- filter(to_plot, is_sync == 1)
to_plot_sync <- mutate(to_plot_sync, n = ifelse(n == 0, NA, n))
to_plot_async <- filter(to_plot, is_sync == 0)

p <- ggplot(to_plot) +
    geom_point(data = to_plot_async, aes(x = date_r, y = n,
                                         group = during_sync_chat,
                                         color = during_sync_chat), size = 1.25) +
    geom_line(data = to_plot_async, aes(x = date_r, y = n,
                                        group = during_sync_chat,
                                        color = during_sync_chat), size = .7) +
    geom_point(data = to_plot_sync, aes(x = date_r, y = n,
                                        group = during_sync_chat,
                                        color = during_sync_chat), shape = 8, size = 1.25) +
    scale_color_brewer("", type = "qual", palette = 2) +
    xlab(NULL) +
    ylab("Number of Tweets") +
    scale_x_date(breaks = seq(as.Date("2015-09-01", tz = "America/Detroit"),
                              as.Date("2016-08-31", tz = "America/Detroit"),
                              by = "2 months"),
                 date_labels = "%b %g") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    theme(legend.position = "bottom") +
    theme_bw()

p

ggsave("sync-async-time-series.png", width = 7, height = 5)
```

## Number of synchronous vs. asynchronous tweets

```{r}
d %>% nrow()  # total number of tweets
#d %>% janitor::tabyl(is_sync)
sync_n <- d %>% janitor::tabyl(is_sync) %>% filter(is_sync==1) %>% pull(n)
async_n <- d %>% janitor::tabyl(is_sync) %>% filter(is_sync==0) %>% pull(n)
sync_n; async_n
#(sync_n + async_n) - (d %>% nrow())  # make sure all rows are accounted for
## test if difference is significant
chisq.test(c(sync_n, async_n))


d

library(lme4)
sjPlot::tab_model(glm(is_sync ~ 1, data = d, family = "poisson"), show.se = TRUE)
glmer(is_sync ~ 1 + (1|screen_name), data = d, family = "poisson")

d_quote <- d %>% filter(is_quote)
d_quote
glm(is_sync ~ 1, data = d_quote, family = "poisson")
glmer(is_sync ~ 1 + (1|screen_name), data = d_quote, family = "poisson")
```

## Number of synchronous vs. asynchronous / original vs. nonoriginal tweeters

```{r}
## Number of distinct tweeters
d %>% pull(screen_name) %>% tolower() %>% unique() %>% length()
tweeters_df <- d %>% 
    mutate(screen_name = screen_name %>% tolower) %>%
    group_by(is_sync) %>% 
    summarize(unique_tweeters = (screen_name %>% unique %>% length))
sync_tweeters_n <- tweeters_df %>% filter(is_sync==1) %>% pull(unique_tweeters)
async_tweeters_n <- tweeters_df %>% filter(is_sync==0) %>% pull(unique_tweeters)
sync_tweeters_n; async_tweeters_n
both <- d %>% count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 2)
both_n <- both %>% nrow()
only_one <- d %>% count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1)
sync_only_n <- d %>% semi_join(only_one, by="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
async_only_n <- d %>% semi_join(only_one, by="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
paste("Both:", both_n); paste("Sync Only:", sync_only_n); paste("Async Only:", async_only_n)
only_one_original <- d %>% count(screen_name, is_retweet) %>% 
    count(screen_name) %>% filter(n == 1)
both_original <- d %>% count(screen_name, is_retweet) %>% 
    count(screen_name) %>% filter(n == 2)
both_original_n <- both_original %>% nrow()
sync_only_original <- d %>%
    semi_join(only_one, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1 & !is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
sync_only_nonoriginal <- d %>% semi_join(only_one, by="screen_name") %>%
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1 & is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
sync_only_both <- d %>% semi_join(both_original, by="screen_name") %>%
    semi_join(only_one, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
paste("Total Sync:", sync_only_n); paste("Sync, Original Only", sync_only_original); paste("Sync, Nonoriginal Only", sync_only_nonoriginal); paste("Sync, Original and Nonoriginal", sync_only_both); paste("Total Check:", sync_only_original + sync_only_nonoriginal + sync_only_both)
async_only_original <- d %>% 
    semi_join(only_one, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0 & !is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
async_only_nonoriginal <- d %>% semi_join(only_one, by="screen_name") %>%
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0 & is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
async_only_both <- d %>% semi_join(both_original, by="screen_name") %>%
    semi_join(only_one, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
paste("Total Async:", async_only_n); paste("Async, Original Only", async_only_original); paste("Async, Nonoriginal Only", async_only_nonoriginal); paste("Async, Original and Nonoriginal", async_only_both); paste("Total Check:", async_only_original + async_only_nonoriginal + async_only_both)
both_original_ <- d %>% 
    semi_join(both, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(!is_retweet) %>%
    count(screen_name, is_retweet) %>% 
    count(screen_name) %>% 
    nrow()
both_nonoriginal <- d %>% semi_join(both, by="screen_name") %>%
    semi_join(both, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_retweet) %>%
    count(screen_name, is_retweet) %>% 
    count(screen_name) %>% 
    nrow()
both_both <- d %>% semi_join(both_original, by="screen_name") %>%
    semi_join(both, by="screen_name") %>% 
    mutate(screen_name = screen_name %>% tolower) %>%
    count(screen_name, is_retweet) %>% 
    count(screen_name) %>% 
    nrow()
paste("Total Both:", both_n); paste("Both, Original Only", both_original_); paste("Both, Nonoriginal Only", both_nonoriginal); paste("Both, Original and Nonoriginal", both_both); paste("Total Check:", both_original_ + both_nonoriginal + both_both)
chisq.test(rbind(c(sync_only_original, async_only_original, both_original_),
                 c(sync_only_nonoriginal, async_only_nonoriginal, both_nonoriginal),
                 c(sync_only_both, async_only_both, both_both)))

chisq.test(rbind(c(sync_only_original, async_only_original, both_original_),
                 c(sync_only_nonoriginal, async_only_nonoriginal, both_nonoriginal),
                 c(sync_only_both, async_only_both, both_both)))

rbind(c(sync_only_original, async_only_original, both_original_),
                 c(sync_only_nonoriginal, async_only_nonoriginal, both_nonoriginal),
                 c(sync_only_both, async_only_both, both_both))
```

# RQs 2-4: Content, Interactions, Portals

```{r}
prepped_data %>% 
    select(-is_sync) %>% 
    gather(key, val) %>% 
    ggplot(aes(x = val)) +
    geom_histogram() +
    facet_wrap(~key)
```

```{r}

safe_log <- function(x) {
    ifelse(x == 0, 0, log(x))
}

dd <- prepped_data %>% 
    mutate(cog_proc = safe_log(`Cognitive Processing`)) 
hist(dd$cog_proc)
psych::describe(dd$cog_proc)
library(lme4)
m1 <- lm(`Cognitive Processing` ~ is_sync, data = prepped_data)
summary(m1)
m1lmer <- lmer(`Cognitive Processing` ~ is_sync + (1|screen_name), data = prepped_data)
summary(m1lmer)
sjstats::icc(m1lmer)

m2lmer <- glm(Replies ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data)
summary(m2lmer)
exp(2.32)
sjstats::icc(m2lmer)
```

Note - the below is commented out as in the review process we decided to cut the multivariate tests (due to other changes we made).

<!-- Prior to answering the second through fourth research questions, we examined whether there were multivariate differences in the three groups of outcomes (i.e., content, interaction, and portals) using a Hotelling's T-squared test. -->

<!-- ```{r, eval = FALSE} -->
<!-- # content -->
<!-- prepped_data1 <- select(prepped_data, is_sync:`Work-related Concerns`) -->
<!-- fit1 = hotelling.test(. ~ is_sync, data = prepped_data1) -->
<!-- fit1 -->

<!-- # interactions -->
<!-- prepped_data2 <- select(prepped_data, is_sync, Likes:Mentions) -->
<!-- fit2 = hotelling.test(. ~ is_sync, data = prepped_data2) -->
<!-- fit2 -->

<!-- # portals -->
<!-- prepped_data3 <- select(prepped_data, is_sync, Hashtags, URLs) -->
<!-- fit3 = hotelling.test(. ~ is_sync, data = prepped_data3) -->
<!-- fit3 -->
<!-- ``` -->

This creates a table for the subsequent analyses.

```{r}
mean_stats <- prepped_data %>% 
    select(-screen_name) %>% 
    group_by(is_sync) %>% 
    summarize_all(funs(mean, sd, n())) %>% 
    gather(key, val, -is_sync) %>% 
    separate(key, c("var", "stat"), sep = "\\_") %>% 
    spread(stat, val) %>% 
    mutate(se = sd / sqrt(n - 1)) %>% 
    mutate(is_sync = factor(is_sync, labels = c("Asynchronous", "Synchronous"))) %>% 
    mutate(mean_se = str_c(round(mean, 3), " (", round(se, 3), ")")) %>% 
    select(is_sync, var, mean_se) %>% 
    spread(is_sync, mean_se) %>% 
    mutate(group = c(
        "content",
        "portals",
        "interactions",
        "interactions",
        "content",
        "content",
        "interactions",
        "interactions", 
        "content", 
        "portals",
        "content"
    )) %>% 
    arrange(group, var)
```

Note - we replace these with multi-level LMs and GLMS, as below.

<!-- ## t-tests -->

<!-- ```{r} -->
<!-- test_data <- prepped_data %>%  -->
<!--     select(-is_sync, -screen_name) %>%  -->
<!--     map(~ t.test(. ~ prepped_data$is_sync)) %>%  -->
<!--     map_df(broom::tidy) %>%  -->
<!--     mutate(var = names(prepped_data[, -c(1:2)])) -->

<!-- test_data_joined <- test_data %>%  -->
<!--     mutate(statistic = abs(statistic),  -->
<!--            t = ifelse(p.value > .001,  -->
<!--                       str_c(round(statistic, 3), " p = (", round(p.value, 3), ")"), -->
<!--                       str_c(round(statistic, 3), " p < .001")), -->
<!--            d = compute.es::tes(test_data$statistic,  -->
<!--                                n.1 = 27361, n.2 = 8744, verbose = F)$d, -->
<!--            d = abs(d)) %>%  -->
<!--     select(var, t, d) -->
<!-- ``` -->

```{r}
library(lme4)

m1 <- lmer(Social ~ is_sync + (1|screen_name), data = prepped_data)
m2 <- lmer(`Cognitive Processing` ~ is_sync + (1|screen_name), data = prepped_data)
m3 <- lmer(`Positive Affect` ~ is_sync + (1|screen_name), data = prepped_data)
m4 <- lmer(`Negative Affect` ~ is_sync + (1|screen_name), data = prepped_data)
m5 <- lmer(`Work-related Concerns` ~ is_sync + (1|screen_name), data = prepped_data)

m7 <- glmer(Retweets ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data,
            control = glmerControl(optimizer = "nloptwrap"))
m8 <- glmer(Replies ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data)

# warning for m9
m90 <- glmer(Mentions ~ 1 + (1|screen_name), family = "poisson", data = prepped_data)
performance:icc(m90)
m9 <- glmer(Mentions ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data,
            control = glmerControl(
                           optimizer = "nloptwrap"))

m10 <- glmer(Hashtags ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data)
m11 <- glmer(URLs ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data)
m12 <- glmer(Likes ~ is_sync + (1|screen_name), family = "poisson", data = prepped_data)
```

```{r}
get_stats <- function(m) {
  x <- broom::tidy(m)
  o <- filter(x, group == "fixed")
  o <- mutate(o, est_se = str_c(round(estimate, 3), " (", round(std.error, 3), ")")) 
  o <- as.vector(unlist(select(o, est_se)))
  i <- round(as.vector(performance::icc(m))[[1]][1], 3)
  
  d <- data.frame(int_est_se = o[1], sync_est_se = o[2], icc = i)
  return(d)
}

l <- list(m2, m3, m1, m5, m4, 
          m8, m7, m9, m12, 
          m10, m11) %>% 
  map_df(get_stats)

l %>% clipr::write_clip()

EMAtools::lme.dscore(m4, data = prepped_data, type = "lme4")
```

## Joining Tables

This prints the table and also writes it to a CSV, so that it can be added to the manuscript separately.

```{r}
combined_table <- mean_stats %>% 
    left_join(test_data_joined, by = "var") %>% 
    select(group, var, Asynchronous, Synchronous, t, d) %>% 
    arrange(group, desc(d))
combined_table

combined_table %>% write_csv("combined-table-for-publication.csv")
```

## Number of synchronous vs. asynchronous  quote tweets

```{r}
d %>% filter(is_quote==TRUE) %>% nrow()  # total number of quote tweets
sync_quote_n <- d %>% filter(is_quote==TRUE) %>% 
    janitor::tabyl(is_sync) %>% filter(is_sync==1) %>% pull(n)
async_quote_n <- d %>% filter(is_quote==TRUE) %>%
    janitor::tabyl(is_sync) %>% filter(is_sync==0) %>% pull(n)
sync_quote_n; async_quote_n

## test if difference is significant
chisq.test(c(sync_quote_n, async_quote_n))
```

## creates categorical variables for sync/async; original/retweet

```{r}

# Variable 1, a categorical with: only sync, only async, both async and sync

sync_names <- d %>% filter(is_sync == TRUE) %>% pull(screen_name) %>% unique()
async_names <- d %>% filter(is_sync == FALSE) %>% pull(screen_name) %>% unique()

both_names <- sync_names[sync_names %in% async_names]

only_sync <- sync_names[!sync_names %in% both_names]
only_async <- async_names[!async_names %in% both_names]

d <- d %>% mutate(sync_categorical = ifelse(screen_name %in% both_names, "both", ifelse(screen_name %in% only_sync, "sync", "async")))

# Variable 2, a categorical with: only original, only retweeting, and original and retweeting

original_names <- d %>% filter(is_retweet == FALSE) %>% pull(screen_name) %>% unique()
retweet_names <- d %>% filter(is_retweet == TRUE) %>% pull(screen_name) %>% unique()

both_o_names <- original_names[original_names %in% retweet_names]

only_retweet <- retweet_names[!retweet_names %in% both_o_names]
only_original <- original_names[!original_names %in% both_o_names]

both_o_names %>% length()

d <- d %>% mutate(original_categorical = ifelse(screen_name %in% both_o_names, "both", ifelse(screen_name %in% only_original, "original", "retweet")))

d %>% filter(original_categorical == "retweet") %>% pull(screen_name)%>% unique() %>% length()

```

# R version and package info

Note that this is the version of R and of packages used to render this document.

```{r}
sessionInfo()
```