---
title: "Sync-Async Analysis"
author: "Spencer P. Greenhalgh, Joshua M. Rosenberg, & K. Bret Staudt Willet"
date: "5/20/2019"
output: 
    html_document:
        toc: true
        float_toc: true
---

# Loading the data and setting up

This section loads the data and packages and starts to process the data, but doesn't calculate any statistics or create any results.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
usethis::use_git_ignore(c("*.csv", "*.rds"))
```

## Loading packages

```{r, include=FALSE}
library(tidyverse)
library(rtweet)
library(lubridate)
library(janitor)
library(Hotelling)
#library(devtools)  # need to install if not installed
#devtools::install_github("jrosen48/tidyttest")  # only need to run once
library(tidyttest)
```

## Getting data from Open Science Framework

For notes on this one-time setup, see this walkthrough: http://centerforopenscience.github.io/osfr/articles/auth.html)

First, you must generate an API token from an OSF account that has been added to the data repository. Read how to do this here: https://developer.osf.io/#tag/General-Usage

Then, you need to add the OSF API token to the `.renviron` file, which is created using the following command. Here, the file is created at the user level, although this could also be set to the project level. 

```{r, eval = FALSE}
usethis::edit_r_environ(scope='user')
```

Open the `.renviron` file and add a single line, using this exact text but replacing `<token>` with your OSF API token:  
`OSF_PAT="<token>"`

Save the file, quit R, and restart in a new session. Continue running the R script from here.

--------------------------------------------------------------------------------

Now, install the `osfr` package and load the library:

```{r, eval = FALSE}
devtools::install_github("centerforopenscience/osfr")   # only need to run once
library(osfr) 
```

Upon loading the `osfr` package, you should see this message:  
`Automatically registered OSF personal access token.` 

Now you are able to retrieve and download the relevant dataset with this code:

```{r, eval = FALSE}
osf_retrieve_file("https://osf.io/ktm2s/?pid=m25zy") %>% 
    osf_download(path = "sync-async-dataset.csv", overwrite = TRUE)
```

## Loading the data

Note that we first processed data collected via TAGS in order to obtain the tweet IDs, which we then passed to the `lookup_statuses()` rtweet function. That code is in `analysis-background_data_processing.Rmd`.

```{r, include=FALSE}
d <- read_csv("sync-async-dataset.csv", skip=1)

names(d)[1:91] <- c("user_id", "status_id", "created_at", "screen_name", "text", 
                        "source", "display_text_width", "reply_to_status_id", "reply_to_user_id", 
                        "reply_to_screen_name", "is_quote", "is_retweet", "favorite_count", 
                        "retweet_count", "hashtags", "symbols", "urls_url", "urls_t.co", 
                        "urls_expanded_url", "media_url", "media_t.co", "media_expanded_url", 
                        "media_type", "ext_media_url", "ext_media_t.co", "ext_media_expanded_url", 
                        "ext_media_type", "mentions_user_id", "mentions_screen_name", 
                        "lang", "quoted_status_id", "quoted_text", "quoted_created_at", 
                        "quoted_source", "quoted_favorite_count", "quoted_retweet_count", 
                        "quoted_user_id", "quoted_screen_name", "quoted_name", "quoted_followers_count", 
                        "quoted_friends_count", "quoted_statuses_count", "quoted_location", 
                        "quoted_description", "quoted_verified", "retweet_status_id", 
                        "retweet_text", "retweet_created_at", "retweet_source", "retweet_favorite_count", 
                        "retweet_retweet_count", "retweet_user_id", "retweet_screen_name", 
                        "retweet_name", "retweet_followers_count", "retweet_friends_count", 
                        "retweet_statuses_count", "retweet_location", "retweet_description", 
                        "retweet_verified", "place_url", "place_name", "place_full_name", 
                        "place_type", "country", "country_code", "geo_coords", "coords_coords", 
                        "bbox_coords", "status_url", "name", "location", "description", 
                        "url", "protected", "followers_count", "friends_count", "listed_count", 
                        "statuses_count", "favourites_count", "account_created_at", "verified", 
                        "profile_url", "profile_expanded_url", "account_lang", "profile_banner_url", 
                        "profile_background_url", "profile_image_url", "date", "is_sync", 
                        "type")

names(d)[92:ncol(d)] <- c("WC", "Analytic", "Clout", "Authentic", "Tone", "WPS", "Sixltr", 
                                  "Dic", "function", "pronoun", "ppron", "i", "we", "you", "shehe", 
                                  "they", "ipron", "article", "prep", "auxverb", "adverb", "conj", 
                                  "negate", "verb", "adj", "compare", "interrog", "number", "quant", 
                                  "affect", "posemo", "negemo", "anx", "anger", "sad", "social", 
                                  "family", "friend", "female", "male", "cogproc", "insight", "cause", 
                                  "discrep", "tentat", "certain", "differ", "percept", "see", "hear", 
                                  "feel", "bio", "body", "health", "sexual", "ingest", "drives", 
                                  "affiliation", "achieve", "power", "reward", "risk", "focuspast", 
                                  "focuspresent", "focusfuture", "relativ", "motion", "space", 
                                  "time", "work", "leisure", "home", "money", "relig", "death", 
                                  "informal", "swear", "netspeak", "assent", "nonflu", "filler", 
                                  "AllPunc", "Period", "Comma", "Colon", "SemiC", "QMark", "Exclam", 
                                  "Dash", "Quote", "Apostro", "Parenth", "OtherP")

```

## Processing the data

Fixing hashtags and URLs using regex.

```{r}
hashtag_pattern <- "#([0-9]|[a-zA-Z])+"
link_pattern <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"

d <- mutate(d, 
            hashtags_count = str_count(text, hashtag_pattern),
            urls_count = str_count(text, link_pattern))
```

```{r}
reply_tweets <- d %>% 
    mutate(is_reply = !is.na(reply_to_status_id)) %>% 
    filter(is_reply) %>% 
    count(reply_to_status_id) %>% 
    rename(replies_count = n)

length_with_na <- function(x) {
  ifelse(is.na(x), 0, map_int(x, length))
}

proc_tweets <- function(d) {
  d %>%
    mutate(mentions_count = length_with_na(str_split(mentions_screen_name, " ")),
           #hashtags_count = length_with_na(str_split(hashtags, " ")),
           #urls_count = length_with_na(str_split(urls_url, " ")),
           is_reply = if_else(!is.na(reply_to_status_id), TRUE, FALSE))
}

d <- proc_tweets(d)

is.na(d$is_sync) %>% which()  # check to make sure there are no NAs

prepped_data <- d %>% 
    filter(!is_retweet) %>% 
    mutate(reply_to_status_id = status_id) %>% 
    left_join(reply_tweets, by = "reply_to_status_id") %>% 
    mutate(replies_count = ifelse(is.na(replies_count), 0, replies_count)) %>% 
    select(is_sync,
           social, cogproc, posemo, negemo, work,
           favorite_count, retweet_count, replies_count, 
           mentions_count, hashtags_count, urls_count) %>% 
    rename(Social = social,
           `Cognitive Processing` = cogproc,
           `Positive Affect` = posemo,
           `Negative Affect` = negemo,
           `Work-related Concerns` = work) %>% 
    rename(Likes = favorite_count,
           Retweets = retweet_count,
           Replies = replies_count,
           Mentions = mentions_count) %>% 
    rename(Hashtags = hashtags_count,
           URLs = urls_count)
```

# RQ1: Activity

## Plot: Sync vs. Async

```{r}
d$created_at_m <- d$created_at - lubridate::hours(5)
d$date_r <- d$created_at_m %>% floor_date("day")

to_plot <- d %>% count(date_r, is_sync) %>% as.data.frame %>%
    tidyr::complete(date_r, is_sync, fill = list(n = 0)) %>%
    filter(date_r != ymd("2015-08-31")) %>%
    mutate(date_r = date_r %>% as_date,
           during_sync_chat = as.factor(is_sync)
    ) 
levels(to_plot$during_sync_chat) <- c('Not During a Chat (Asynchronous)',
                                      'During a Chat (Synchronous)')

to_plot_sync <- filter(to_plot, is_sync == 1)
to_plot_sync <- mutate(to_plot_sync, n = ifelse(n == 0, NA, n))
to_plot_async <- filter(to_plot, is_sync == 0)

p <- ggplot(to_plot) +
    geom_point(data = to_plot_async, aes(x = date_r, y = n,
                                         group = during_sync_chat,
                                         color = during_sync_chat), size = 1.25) +
    geom_line(data = to_plot_async, aes(x = date_r, y = n,
                                        group = during_sync_chat,
                                        color = during_sync_chat), size = .7) +
    geom_point(data = to_plot_sync, aes(x = date_r, y = n,
                                        group = during_sync_chat,
                                        color = during_sync_chat), shape = 8, size = 1.25) +
    scale_color_brewer("", type = "qual", palette = 2) +
    xlab(NULL) +
    ylab("Number of Tweets") +
    scale_x_date(breaks = seq(as.Date("2015-09-01", tz = "America/Detroit"),
                              as.Date("2016-08-31", tz = "America/Detroit"),
                              by = "2 months"),
                 date_labels = "%b %g") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    theme(legend.position = "bottom") +
    theme_bw()

p

ggsave("async-sync-time-series.png", width = 7, height = 5)
```

## Number of synchronous vs. asynchronous tweets

```{r}
d %>% nrow()  # total number of tweets
#d %>% janitor::tabyl(is_sync)
sync_n <- d %>% janitor::tabyl(is_sync) %>% filter(is_sync==1) %>% pull(n)
async_n <- d %>% janitor::tabyl(is_sync) %>% filter(is_sync==0) %>% pull(n)
sync_n; async_n
#(sync_n + async_n) - (d %>% nrow())  # make sure all rows are accounted for
## test if difference is significant
chisq.test(c(sync_n, async_n))
```

## Number of synchronous vs. asynchronous / original vs. nonoriginal tweeters

```{r}
## Number of distinct tweeters
d %>% pull(screen_name) %>% tolower() %>% unique() %>% length()
tweeters_df <- d %>% 
    mutate(screen_name = screen_name %>% tolower) %>%
    group_by(is_sync) %>% 
    summarize(unique_tweeters = (screen_name %>% unique %>% length))
sync_tweeters_n <- tweeters_df %>% filter(is_sync==1) %>% pull(unique_tweeters)
async_tweeters_n <- tweeters_df %>% filter(is_sync==0) %>% pull(unique_tweeters)
sync_tweeters_n; async_tweeters_n
both <- d %>% count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 2)
both_n <- both %>% nrow()
only_one <- d %>% count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1)
sync_only_n <- d %>% semi_join(only_one, by="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
async_only_n <- d %>% semi_join(only_one, by="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
paste("Both:", both_n); paste("Sync Only:", sync_only_n); paste("Async Only:", async_only_n)
only_one_original <- d %>% count(screen_name, is_retweet) %>% 
    count(screen_name) %>% filter(n == 1)
both_original <- d %>% count(screen_name, is_retweet) %>% 
    count(screen_name) %>% filter(n == 2)
both_original_n <- both_original %>% nrow()
sync_only_original <- d %>%
    semi_join(only_one, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1 & !is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
sync_only_nonoriginal <- d %>% semi_join(only_one, by="screen_name") %>%
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1 & is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
sync_only_both <- d %>% semi_join(both_original, by="screen_name") %>%
    semi_join(only_one, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==1) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
paste("Total Sync:", sync_only_n); paste("Sync, Original Only", sync_only_original); paste("Sync, Nonoriginal Only", sync_only_nonoriginal); paste("Sync, Original and Nonoriginal", sync_only_both); paste("Total Check:", sync_only_original + sync_only_nonoriginal + sync_only_both)
async_only_original <- d %>% 
    semi_join(only_one, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0 & !is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
async_only_nonoriginal <- d %>% semi_join(only_one, by="screen_name") %>%
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0 & is_retweet) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
async_only_both <- d %>% semi_join(both_original, by="screen_name") %>%
    semi_join(only_one, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_sync==0) %>%
    count(screen_name, is_sync) %>% 
    count(screen_name) %>% filter(n == 1) %>% 
    nrow()
paste("Total Async:", async_only_n); paste("Async, Original Only", async_only_original); paste("Async, Nonoriginal Only", async_only_nonoriginal); paste("Async, Original and Nonoriginal", async_only_both); paste("Total Check:", async_only_original + async_only_nonoriginal + async_only_both)
both_original_ <- d %>% 
    semi_join(both, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(!is_retweet) %>%
    count(screen_name, is_retweet) %>% 
    count(screen_name) %>% 
    nrow()
both_nonoriginal <- d %>% semi_join(both, by="screen_name") %>%
    semi_join(both, by="screen_name") %>% 
    semi_join(only_one_original, by ="screen_name") %>%
    mutate(screen_name = screen_name %>% tolower) %>%
    filter(is_retweet) %>%
    count(screen_name, is_retweet) %>% 
    count(screen_name) %>% 
    nrow()
both_both <- d %>% semi_join(both_original, by="screen_name") %>%
    semi_join(both, by="screen_name") %>% 
    mutate(screen_name = screen_name %>% tolower) %>%
    count(screen_name, is_retweet) %>% 
    count(screen_name) %>% 
    nrow()
paste("Total Both:", both_n); paste("Both, Original Only", both_original_); paste("Both, Nonoriginal Only", both_nonoriginal); paste("Both, Original and Nonoriginal", both_both); paste("Total Check:", both_original_ + both_nonoriginal + both_both)
chisq.test(rbind(c(sync_only_original, async_only_original, both_original_),
                 c(sync_only_nonoriginal, async_only_nonoriginal, both_nonoriginal),
                 c(sync_only_both, async_only_both, both_both)))
```

# RQs 2-4: Content, Interactions, Portals

## Hotelling's test

Prior to answering the second through fourth research questions, we examined whether there were multivariate differences in the three groups of outcomes (i.e., content, interaction, and portals) using a Hotelling's T-squared test.

```{r}
# content
prepped_data1 <- select(prepped_data, is_sync:`Work-related Concerns`)
fit1 = hotelling.test(. ~ is_sync, data = prepped_data1)
fit1

# interactions
prepped_data2 <- select(prepped_data, is_sync, Likes:Mentions)
fit2 = hotelling.test(. ~ is_sync, data = prepped_data2)
fit2

# portals
prepped_data3 <- select(prepped_data, is_sync, Hashtags, URLs)
fit3 = hotelling.test(. ~ is_sync, data = prepped_data3)
fit3
```

This creates a table for the subsequent analyses.

```{r}
mean_stats <- prepped_data %>% 
    group_by(is_sync) %>% 
    summarize_all(funs(mean, sd, n())) %>% 
    gather(key, val, -is_sync) %>% 
    separate(key, c("var", "stat"), sep = "\\_") %>% 
    spread(stat, val) %>% 
    mutate(se = sd / sqrt(n - 1)) %>% 
    mutate(is_sync = factor(is_sync, labels = c("Asynchronous", "Synchronous"))) %>% 
    mutate(mean_se = str_c(round(mean, 3), " (", round(se, 3), ")")) %>% 
    select(is_sync, var, mean_se) %>% 
    spread(is_sync, mean_se) %>% 
    mutate(group = c(
        "content",
        "portals",
        "interactions",
        "interactions",
        "content",
        "content",
        "interactions",
        "interactions", 
        "content", 
        "portals",
        "content"
    )) %>% 
    arrange(group, var)
```

## t-tests

```{r}
test_data <- prepped_data %>% 
    select(-is_sync) %>% 
    map(~ t.test(. ~ prepped_data$is_sync)) %>% 
    map_df(broom::tidy) %>% 
    mutate(var = names(prepped_data[, -1]))

test_data_joined <- test_data %>% 
    mutate(statistic = abs(statistic), 
           t = ifelse(p.value > .001, 
                      str_c(round(statistic, 3), " p = (", round(p.value, 3), ")"),
                      str_c(round(statistic, 3), " p < .001")),
           d = compute.es::tes(test_data$statistic, 
                               n.1 = 27361, n.2 = 8744, verbose = F)$d,
           d = abs(d)) %>% 
    select(var, t, d)
```

## Joining Tables

This prints the table and also writes it to a CSV, so that it can be added to the manuscript separately.

```{r}
combined_table <- mean_stats %>% 
    left_join(test_data_joined, by = "var") %>% 
    select(group, var, Asynchronous, Synchronous, t, d) %>% 
    arrange(group, desc(d))
combined_table

combined_table %>% write_csv("combined-table.csv")
```

## Number of synchronous vs. asynchronous  quote tweets

```{r}
d %>% filter(is_quote==TRUE) %>% nrow()  # total number of quote tweets
sync_quote_n <- d %>% filter(is_quote==TRUE) %>% 
    janitor::tabyl(is_sync) %>% filter(is_sync==1) %>% pull(n)
async_quote_n <- d %>% filter(is_quote==TRUE) %>%
    janitor::tabyl(is_sync) %>% filter(is_sync==0) %>% pull(n)
sync_quote_n; async_quote_n

## test if difference is significant
chisq.test(c(sync_quote_n, async_quote_n))
```